{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "4.1.1\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haar Cascade Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "detect_scale = float(2) #Scale used for Haar cascade detection\n",
    "window_scale = float(2) #Scale of the interactive window\n",
    "\n",
    "window_name = \"Live Face Detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(window_name)\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    rval, frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    rval, frame = vc.read()\n",
    "    \n",
    "    #Preprocess image for detector\n",
    "    frame_detect = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_detect = cv2.resize(frame_detect, (0, 0), fx=detect_scale, fy=detect_scale)\n",
    "    \n",
    "    #Detect faces\n",
    "    faces_q = faceCascade.detectMultiScale(frame_detect, scaleFactor=1.2, minNeighbors=5, minSize=(5, 5), flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    #Draw rectangles on detected faces\n",
    "    for  (x, y, w, h) in faces_q:\n",
    "        cv2.rectangle(frame, (int(x/detect_scale), int(y/detect_scale)), \n",
    "                      (int((x+w)/detect_scale), int((y+h)/detect_scale)), \n",
    "                      (0, 0, 255), 2)\n",
    "\n",
    "    frame = np.flip(frame, 1) #Mirror image for webcam mirror use\n",
    "    frame = cv2.resize(frame, (0, 0), fx=window_scale, fy=window_scale) #Scale the image to fit window size\n",
    "    cv2.imshow(window_name, frame)\n",
    "    \n",
    "    key = cv2.waitKey(5)\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "\n",
    "cv2.destroyWindow(window_name)\n",
    "vc.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORB Features Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MATCH_COUNT = 10\n",
    "\n",
    "img1 = cv2.imread('tag-mosaic.png') # trainImage\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "detect_scale = float(1) #Scale used for ORB detection\n",
    "window_scale = float(2) #Scale of the interactive window\n",
    "\n",
    "window_name = \"ORB Object Detection\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "\n",
    "\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                   table_number = 6, # 12\n",
    "                   key_size = 12,     # 20\n",
    "                   multi_probe_level = 1) #2\n",
    "\n",
    "search_params = dict(checks = 50)\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "cv2.namedWindow(window_name)\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    rval, frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    rval, frame = vc.read()\n",
    "    img2 = cv2.resize(frame, (0, 0), fx=detect_scale, fy=detect_scale)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    try:\n",
    "        # find the keypoints and descriptors with ORB\n",
    "        kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "\n",
    "        matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "        # Need to draw only good matches, so create a mask\n",
    "        matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "        # store all the good matches as per Lowe's ratio test.\n",
    "        good = []\n",
    "        if len(matches) > 0:\n",
    "            for i, v in enumerate(matches):\n",
    "                if len(v) == 2:\n",
    "                    m, n = v\n",
    "                    if m.distance < 0.7*n.distance:\n",
    "                        good.append(m)\n",
    "                        matchesMask[i]=[1,0]\n",
    "\n",
    "        # if enough matches, compute homography\n",
    "        if len(good)>MIN_MATCH_COUNT:\n",
    "            src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "            dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "            matchesMask = mask.ravel().tolist()\n",
    "\n",
    "            h,w,d = img1.shape\n",
    "            pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "\n",
    "            dst = cv2.perspectiveTransform(pts,M)\n",
    "            img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "            \n",
    "    except:\n",
    "        error = 0\n",
    "\n",
    "\n",
    "    frame = img2   \n",
    "        \n",
    "    frame = np.flip(frame, 1) #Mirror image for webcam mirror use\n",
    "    frame = cv2.resize(frame, (0, 0), fx=window_scale, fy=window_scale) #Scale the image to fit window size\n",
    "    cv2.imshow(window_name, frame)\n",
    "    \n",
    "    key = cv2.waitKey(5)\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "\n",
    "cv2.destroyWindow(window_name)\n",
    "vc.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
